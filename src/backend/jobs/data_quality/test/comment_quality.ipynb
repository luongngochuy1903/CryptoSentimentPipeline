{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d863e89-33b7-4928-932a-13219b6dd7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Latest timestamp found: 2025-07-19 04:36:58\n",
      "2025-07-19 04:36:58\n"
     ]
    }
   ],
   "source": [
    "import logging, os, sys\n",
    "from datetime import datetime, timedelta\n",
    "from modules import get_latest_partition_datetime\n",
    "log_dir = \"logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = (datetime.utcnow() + timedelta(hours=7)).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "log_file = os.path.join(log_dir, f\"Comments_{timestamp}.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file, mode='a'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5b1fb-d35d-4abd-a8b0-8d19c959e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 03:40:14,450 - INFO - ------------------NEWS DATA QUALITY------------------\n",
      "2025-07-20 03:40:25,390 - INFO - struct<author:string,published:string,source:string,text:string,title:string,url:string>\n",
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- published: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"------------------COMMENTS DATA QUALITY------------------\")\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read from MinIO via s3a\") \\\n",
    "    .getOrCreate()\n",
    "commentsdf = spark.read.json(\"s3a://raw/comments/\")\n",
    "logger.info(commentsdf.schema.simpleString())\n",
    "commentsdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c55ce5f-66ce-4688-98af-219e3d8e07b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 03:37:31,455 - INFO - Text columns WHICH IS NULL:137\n",
      "2025-07-20 03:37:31,887 - INFO - Published columns WHICH IS NULL:0\n"
     ]
    }
   ],
   "source": [
    "#Checking null\n",
    "from pyspark.sql.functions import col, count\n",
    "num_of_null_title = commentsdf.filter((col(\"title\").isNull()) | (col(\"title\") == \"\")).count()\n",
    "logger.info(f\"Title columns WHICH IS NULL:{num_of_null_title}\")\n",
    "\n",
    "num_of_null_url = commentsdf.filter(col(\"url\").isNull()).count()\n",
    "logger.info(f\"Url columns WHICH IS NULL:{num_of_null_url}\")\n",
    "\n",
    "num_of_null_id = commentsdf.filter(col(\"id\").isNull()).count()\n",
    "logger.info(f\"ID columns WHICH IS NULL:{num_of_null_id}\")\n",
    "\n",
    "num_of_null_selftext = commentsdf.filter(col(\"selftext\").isNull()).count()\n",
    "logger.info(f\"Selftext columns WHICH IS NULL:{num_of_null_selftext}\")\n",
    "\n",
    "num_of_null_score = commentsdf.filter(col(\"score\").isNull()).count()\n",
    "logger.info(f\"Score columns WHICH IS NULL:{num_of_null_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3514783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 03:37:35,213 - INFO - ROW COUNT:733\n"
     ]
    }
   ],
   "source": [
    "#Checking row count\n",
    "num_of_row = commentsdf.count()\n",
    "logging.info(f\"ROW COUNT:{num_of_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c43314-7758-4f37-a727-323e009add46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 03:37:37,968 - INFO - NUMBER of DUPLICATED NEWS: 3\n",
      "2025-07-20 03:37:37,971 - INFO - DUPLICATED NEWS:\n",
      "2025-07-20 03:37:37,974 - INFO - https://www.bbc.com/news/articles/c0k7enxkxndo - What is an Isa and how might the rules change?\n",
      "2025-07-20 03:37:37,983 - INFO - https://www.bbc.com/news/articles/clyndp097gro - Package holidays to Spain, Cyprus and Turkey soar in price\n",
      "2025-07-20 03:37:37,986 - INFO - https://www.bbc.com/news/articles/cq6mvn699v9o - When to book and where to stay: Six ways to save money on your summer holiday\n"
     ]
    }
   ],
   "source": [
    "#Checking duplicated news\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "spec = Window.partitionBy(\"id\").orderBy(\"id\")\n",
    "commentsdf_with_duplicated = commentsdf.withColumn(\"duplicated_id\", row_number().over(spec))\n",
    "record_duplicated = commentsdf_with_duplicated.filter(col(\"duplicated_id\") > 1).select(col('id'), col('title'))\n",
    "record_duplicated_select = record_duplicated.collect()\n",
    "num_record_duplicated = record_duplicated.count()\n",
    "logging.info(f\"NUMBER of DUPLICATED COMMENTS: {num_record_duplicated}\")\n",
    "logging.info(\"DUPLICATED COMMENTS:\")\n",
    "for row in record_duplicated_select:\n",
    "    logger.info(f\"{str(row['id'])} - {str(row['title'])}\")\n",
    "\n",
    "#New df without duplicated url\n",
    "commentsdf = commentsdf_with_duplicated.filter(col(\"duplicated_id\") == 1).drop(\"duplicated_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f85477-6a50-4635-8e48-3d788478ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 03:37:40,899 - INFO - UNIQUE VALUE of author: 109\n",
      "2025-07-20 03:37:41,342 - INFO - UNIQUE VALUE of published: 608\n",
      "2025-07-20 03:37:41,761 - INFO - UNIQUE VALUE of source: 13\n",
      "2025-07-20 03:37:42,173 - INFO - UNIQUE VALUE of text: 588\n",
      "2025-07-20 03:37:42,589 - INFO - UNIQUE VALUE of title: 719\n",
      "2025-07-20 03:37:42,906 - INFO - UNIQUE VALUE of url: 730\n"
     ]
    }
   ],
   "source": [
    "#Checking distinct value\n",
    "for column in commentsdf.columns:\n",
    "    n_unique = commentsdf.select(col(column)).distinct().count()\n",
    "    logger.info(f\"UNIQUE VALUE of {column}: {n_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b029488-29c8-44f2-a906-7b2fbb13f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 03:37:44,160 - INFO - DATATYPE Column author: string\n",
      "2025-07-20 03:37:44,167 - INFO - DATATYPE Column published: string\n",
      "2025-07-20 03:37:44,172 - INFO - DATATYPE Column source: string\n",
      "2025-07-20 03:37:44,180 - INFO - DATATYPE Column text: string\n",
      "2025-07-20 03:37:44,183 - INFO - DATATYPE Column title: string\n",
      "2025-07-20 03:37:44,186 - INFO - DATATYPE Column url: string\n"
     ]
    }
   ],
   "source": [
    "#Checking datatypes\n",
    "for column, dtype in commentsdf.dtypes:\n",
    "    logger.info(f\"DATATYPE Column {column}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6833b-b973-4e0c-845d-4ff3bcfc131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|              author|           published|              source|                text|               title|                 url|       published_ts|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|Lauren Aratani in...|Thu, 10 Jul 2025 ...|https://www.thegu...|As temperatures s...|US shoppers feel ...|https://www.thegu...|2025-07-10 09:00:15|\n",
      "|Dan Milmo Global ...|Thu, 10 Jul 2025 ...|https://www.thegu...|Four people inclu...|Four people arres...|https://www.thegu...|2025-07-10 11:13:06|\n",
      "|    Joanna Partridge|Thu, 10 Jul 2025 ...|https://www.thegu...|Bad management of...|Government inheri...|https://www.thegu...|2025-07-10 23:01:51|\n",
      "|        Nils Pratley|Thu, 10 Jul 2025 ...|https://www.thegu...|The chief executi...|Zonal pricing is ...|https://www.thegu...|2025-07-10 18:36:06|\n",
      "|         Mark Sweney|Thu, 10 Jul 2025 ...|https://www.thegu...|WPP has appointed...|WPP names senior ...|https://www.thegu...|2025-07-10 11:02:45|\n",
      "|    Anna Spargo-Ryan|Fri, 11 Jul 2025 ...|https://www.thegu...|I’m a simple girl...|Welcome to Prime ...|https://www.thegu...|2025-07-11 00:17:50|\n",
      "|  Kalyeena Makortoff|Thu, 10 Jul 2025 ...|https://www.thegu...|Royal Mail has be...|Royal Mail gets g...|https://www.thegu...|2025-07-10 08:24:43|\n",
      "|Luiz Inácio Lula ...|Thu, 10 Jul 2025 ...|https://www.thegu...|The year 2025 sho...|With the world in...|https://www.thegu...|2025-07-10 12:47:24|\n",
      "|           Editorial|Thu, 10 Jul 2025 ...|https://www.thegu...|In 2022, Liz Trus...|The Guardian view...|https://www.thegu...|2025-07-10 17:59:36|\n",
      "|         Mark Sweney|Thu, 10 Jul 2025 ...|https://www.thegu...|Photo agencies ar...|Photo agencies to...|https://www.thegu...|2025-07-10 15:57:02|\n",
      "|Kalyeena Makortof...|Thu, 10 Jul 2025 ...|https://www.thegu...|The government ha...|UK government aba...|https://www.thegu...|2025-07-10 09:45:44|\n",
      "|      Graeme Wearden|Thu, 10 Jul 2025 ...|https://www.thegu...|The FTSE 100 inde...|FTSE 100 hits rec...|https://www.thegu...|2025-07-10 15:49:13|\n",
      "|    Lawrence Douglas|Thu, 10 Jul 2025 ...|https://www.thegu...|Think you know Tr...|Think you know Tr...|https://www.thegu...|2025-07-10 10:00:41|\n",
      "|         Justin Kadi|Thu, 10 Jul 2025 ...|https://www.thegu...|When it comes to ...|Vienna has been d...|https://www.thegu...|2025-07-10 06:00:12|\n",
      "|          Jon Henley|Thu, 10 Jul 2025 ...|https://www.thegu...|A unique if well-...|Jane Birkin’s ori...|https://www.thegu...|2025-07-10 17:40:39|\n",
      "|Callum Jones in N...|Thu, 10 Jul 2025 ...|https://www.thegu...|Brazil threatened...|Lula threatens 50...|https://www.thegu...|2025-07-10 18:52:14|\n",
      "|      Guardian Staff|Thu, 10 Jul 2025 ...|https://www.thegu...|So now we know – ...|Self-serving Post...|https://www.thegu...|2025-07-10 16:20:44|\n",
      "|      Sandra Laville|Thu, 10 Jul 2025 ...|https://www.thegu...|South West Water ...|South West Water ...|https://www.thegu...|2025-07-10 14:04:21|\n",
      "|Robert Booth UK t...|Wed, 09 Jul 2025 ...|https://www.thegu...|Google has agreed...|UK government’s d...|https://www.thegu...|2025-07-09 15:42:34|\n",
      "|      George Hibberd|Thu, 10 Jul 2025 ...|https://www.thegu...|I love flying. I’...|Climate anxiety m...|https://www.thegu...|2025-07-10 09:30:40|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "2025-07-20 03:40:56,936 - INFO - MIN DATE: 2025-04-13\n",
      "2025-07-20 03:40:57,388 - INFO - MAX DATE: 2025-07-11\n",
      "✅ Latest timestamp found: 2025-07-19 04:36:58\n",
      "2025-07-20 03:40:57.600875\n",
      "2025-07-20 03:40:58,128 - INFO - SUM OF RECORD after filtering TIMESTAMP: 0\n"
     ]
    }
   ],
   "source": [
    "#checking date\n",
    "from pyspark.sql.functions import to_timestamp, to_date, min, max, udf\n",
    "from pyspark.sql.types import TimestampType\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "@udf(returnType=TimestampType())\n",
    "def clean_and_parse_published(published):\n",
    "    try:\n",
    "        if published is None:\n",
    "            return None\n",
    "        return datetime.utcfromtimestamp(int(published))\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to parse: {published} | Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "commentsdf = commentsdf.withColumn(\"created_utc\", clean_and_parse_published(col(\"created_utc\")))\n",
    "commentsdf.show(20)\n",
    "min_date_row = commentsdf.agg(min(to_date(col(\"created_utc\"))).alias(\"min_date\")).collect()[0]\n",
    "min_date = min_date_row[\"min_date\"]\n",
    "logger.info(f\"MIN DATE: {min_date}\")\n",
    "\n",
    "max_date_row = commentsdf.agg(max(to_date(col(\"created_utc\"))).alias(\"max_date\")).collect()[0]\n",
    "max_date = max_date_row[\"max_date\"]\n",
    "logger.info(f\"MAX DATE: {max_date}\")\n",
    "\n",
    "# #Eliminate old published from nearest scraped timestamp to now\n",
    "# latest_update = get_latest_partition_datetime(\"raw\", \"comments\")\n",
    "# today = datetime.today()\n",
    "# print(today)\n",
    "\n",
    "# commentsdf = commentsdf.filter((col('created_utc') > latest_update) & (col('created_utc') <= today))\n",
    "# sumcount = commentsdf.count()\n",
    "# logger.info(f\"SUM OF RECORD after filtering TIMESTAMP: {sumcount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81439d94-502f-46da-b749-d024657ea05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model reflecting which content is related to domain topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
